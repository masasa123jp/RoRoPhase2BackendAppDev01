"""
ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ (backend/app/main.py)
======================================================
* FastAPI ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ç”Ÿæˆ
* ä¾å­˜ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ï¼ˆCORS / OpenTelemetry / ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆï¼‰ã®çµ„ã¿è¾¼ã¿
* API ãƒ«ãƒ¼ã‚¿ãƒ¼ã®è‡ªå‹•ç™»éŒ²
* ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ï¼ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒãƒ³ãƒ‰ãƒ©ã§å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ã‚’ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
--------------------------------------------------------------------
ã“ã®ãƒ•ã‚¡ã‚¤ãƒ« 1 æœ¬ã‚’ `uvicorn app.main:app` ã§èµ·å‹•ã™ã‚Œã°
Azure App Serviceï¼ˆDocker ã‚³ãƒ³ãƒ†ãƒŠï¼‰ã§ã‚‚ãƒ­ãƒ¼ã‚«ãƒ«ã§ã‚‚åŒä¸€æŒ™å‹•ã«ãªã‚‹ã€‚
"""

from __future__ import annotations

import asyncio
import importlib
import logging
from pathlib import Path
from typing import Any

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

# ãƒ¬ãƒ¼ãƒˆåˆ¶å¾¡
from slowapi import Limiter
from slowapi.middleware import SlowAPIMiddleware

# OpenTelemetry
from opentelemetry import trace
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.sdk.resources import Resource
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

from .core.config import get_settings
from .core.logging import configure_logging  # ç‹¬è‡ª logging è¨­å®šãƒ˜ãƒ«ãƒ‘
from .core import security  # ensure JWT utils are imported once

settings = get_settings()
logger = configure_logging()

# ------------------------------------------------------------------
# Limiter æº–å‚™: 1 IP 100 req/minï¼ˆå¿…è¦ã«å¿œã˜ç’°å¢ƒå¤‰æ•°ã§èª¿æ•´å¯ï¼‰
limiter = Limiter(key_func=lambda request: request.client.host, default_limits=["100/minute"])

# ------------------------------------------------------------------
# OpenTelemetry åˆæœŸåŒ–
resource = Resource.create({"service.name": settings.project_name})
provider = TracerProvider(resource=resource)
processor = BatchSpanProcessor(OTLPSpanExporter())  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: http://localhost:4318
provider.add_span_processor(processor)
trace.set_tracer_provider(provider)

# ------------------------------------------------------------------
# FastAPI ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
app = FastAPI(
    title=settings.project_name,
    version=settings.version,
    docs_url="/docs",
    openapi_url="/openapi.json",
    lifespan="on",
)

# --- CORS: Front Door ã®å…¬é–‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’è¨±å¯ --------------------------
app.add_middleware(
    CORSMiddleware,
    allow_origins=[settings.cors_origin or "https://api.roro.com"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["Authorization", "Content-Type"],
)

# --- ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ -------------------------------------
app.state.limiter = limiter
app.add_middleware(SlowAPIMiddleware)

# --- OpenTelemetry è‡ªå‹•è¨ˆæ¸¬ ----------------------------------------
FastAPIInstrumentor.instrument_app(app, tracer_provider=provider, excluded_urls=r"/(docs|openapi\.json)")

# ------------------------------------------------------------------
# ãƒ«ãƒ¼ã‚¿ãƒ¼è‡ªå‹•ç™»éŒ²
def include_routers() -> None:
    """
    api/routes/*.py ã‚’å‹•çš„ãƒ­ãƒ¼ãƒ‰ã—ã€router å¤‰æ•°ã‚’ app ã«ç™»éŒ²ã€‚
    """
    routes_dir = Path(__file__).parent / "api" / "routes"
    for file in routes_dir.glob("*.py"):
        if file.name.startswith("_"):
            continue
        module_name = f"app.api.routes.{file.stem}"
        module = importlib.import_module(module_name)
        router = getattr(module, "router", None)
        if router:
            app.include_router(router)
            logger.debug("ğŸ“Œ Router [%s] registered", module_name)


include_routers()

# ------------------------------------------------------------------
# èµ·å‹•ï¼†çµ‚äº†ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
@app.on_event("startup")
async def on_startup() -> None:
    """
    * DB æ¥ç¶šã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
    * OpenAI ãƒ¢ãƒ‡ãƒ«ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ï¼ˆéåŒæœŸï¼‰
    * ãã®ä»–å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ã®ç–é€šãƒã‚§ãƒƒã‚¯
    """
    from ..shared_lib.db import engine  # é…å»¶ import ã§å¾ªç’°å›é¿

    logger.info("ğŸŸ¢ FastAPI starting upâ€¦")
    try:
        # æ¥ç¶šç¢ºèª (0.5 ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ)
        async with engine.connect() as conn:
            await asyncio.wait_for(conn.execute("SELECT 1"), timeout=0.5)
        logger.info("âœ… PostgreSQL æ¥ç¶š OK")
    except Exception as exc:  # pragma: no cover
        logger.warning("âš ï¸  PostgreSQL æ¥ç¶šãƒã‚§ãƒƒã‚¯å¤±æ•—: %s", exc)

    # OpenAI ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰ï¼ˆä¸¦åˆ—ã§å®Ÿæ–½ï¼‰
    async def preload_openai() -> None:
        try:
            from .utils.openai_client import get_client
            await get_client().chat.completions.create(
                model="gpt-4o-mini", messages=[{"role": "user", "content": "ping"}], max_tokens=1
            )
            logger.info("âœ… OpenAI é€šä¿¡ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å®Œäº†")
        except Exception as exc:
            logger.error("âŒ OpenAI é€šä¿¡å¤±æ•—: %s", exc)

    asyncio.create_task(preload_openai())


@app.on_event("shutdown")
async def on_shutdown() -> None:
    """
    BatchSpanProcessor Flush / DB Engine Dispose ãªã©ã€‚
    """
    logger.info("ğŸ›‘ FastAPI shutting downâ€¦")
    await trace.get_tracer_provider().shutdown()

    from ..shared_lib.db import engine

    await engine.dispose()
